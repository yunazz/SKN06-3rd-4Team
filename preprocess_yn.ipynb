{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf717c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache, SQLiteCache\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e0a070fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_names(folder_path, format=\".pdf\"):\n",
    "    \"\"\"\n",
    "    ì£¼ì–´ì§„ í´ë” ë‚´ì— ìˆëŠ” PDF íŒŒì¼ë“¤ì˜ ì´ë¦„ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    try:\n",
    "        all_files = os.listdir(folder_path)\n",
    "        pdf_files = [file.replace(format,\"\") for file in all_files if file.lower().endswith(format)]\n",
    "        \n",
    "        return pdf_files\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: í´ë” '{folder_path}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6232293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "def load_and_split_tax_law(file_name):\n",
    "    \n",
    "    \"\"\"\n",
    "    PDF íŒŒì¼ë“¤ì„ ì²˜ë¦¬í•˜ì—¬ ì„ë² ë”©ì„ Chroma Vector Storeì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "\n",
    "    file_path = f\"data/tax_law/{file_name}.pdf\"\n",
    "\n",
    "    loader = PyMuPDFLoader(file_path)\n",
    "    load_document = loader.load()\n",
    "\n",
    "    # ì „ì²˜ë¦¬ - ë°˜ë³µ í…ìŠ¤íŠ¸ ì‚­ì œ\n",
    "    delete_pattern_1 = rf\"ë²•ì œì²˜\\s*\\d+\\s*êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„°\\n{file_name.replace('_', ' ')}\\n\" \n",
    "    delete_pattern_2 = r'\\[[\\s\\S]*?\\]'\n",
    "    delete_pattern_3 = r'<[\\s\\S]*?>'\n",
    "    \n",
    "    full_text = \" \".join([document.page_content for document in load_document])\n",
    "    \n",
    "    full_text = re.sub(delete_pattern_1, \"\", full_text)\n",
    "    full_text=re.sub(delete_pattern_2, '', full_text)\n",
    "    full_text=re.sub(delete_pattern_3, '', full_text)\n",
    "    \n",
    "    # ì „ì²˜ë¦¬ - split\n",
    "    split_pattern = r\"\\s*\\n(ì œ\\d+ì¡°(?:ì˜\\d+)?(?:\\([^)]*\\))?)(?=\\s|$)\"\n",
    "    chunks = re.split(split_pattern, full_text)\n",
    "\n",
    "    chunk_docs = []  # ìµœì¢… return í•  list\n",
    "    connected_chunks = [] \n",
    "    current_chunk = \"\"\n",
    "    is_buchik_section = False \n",
    "    \n",
    "    # ì „ì²˜ë¦¬ - ì¼ë°˜ ì¡°í•­ê³¼ ë¶€ì¹™ì˜ ì¡°í•­ê³¼ êµ¬ë³„í•˜ê¸° ìœ„í•´ ì ‘ë‘ì–´ 'ë¶€ì¹™-'ì„ ë„£ìŒ.\n",
    "    for chunk in chunks:\n",
    "        if re.search(r\"\\n\\s*ë¶€ì¹™\", chunk): \n",
    "            is_buchik_section = True\n",
    "\n",
    "        if chunk.startswith(\"ì œ\") and \"ì¡°\" in chunk: \n",
    "            if is_buchik_section:\n",
    "                chunk = \"ë¶€ì¹™-\" + chunk\n",
    "\n",
    "            if current_chunk:\n",
    "                connected_chunks.append(current_chunk.strip())\n",
    "            current_chunk = chunk \n",
    "        else:\n",
    "            current_chunk += f\" {chunk}\" \n",
    "\n",
    "    if current_chunk:\n",
    "        connected_chunks.append(current_chunk.strip())\n",
    "\n",
    "    for chunk in connected_chunks:\n",
    "        pattern =  r\"^(?:ë¶€ì¹™-)?ì œ\\d+ì¡°(?:ì˜\\d*)?(?:\\([^)]*\\))?\"\n",
    "\n",
    "        keyword = []\n",
    "\n",
    "        keyword.append(file_name)\n",
    "        \n",
    "        match = re.search(pattern, chunk)\n",
    "        if match:\n",
    "            word = match.group()\n",
    "            word = re.sub(r'\\s+', ' ', word)\n",
    "            keyword.append(word) \n",
    "            \n",
    "        doc = Document(metadata={\"title\": file_name, \"keyword\":keyword, \"effective_year\": 2025 }, page_content=chunk),\n",
    "        \n",
    "        chunk_docs.extend(doc)\n",
    "        \n",
    "    return chunk_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "20d64a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector store ì— ë„£ì„ ë°ì´í„° document ëª¨ìœ¼ê¸° -> all_documents\n",
    "all_documents = []\n",
    "# load - ì„¸ë²• \n",
    "law_files = get_file_names(\"data/tax_law\")\n",
    "for file in law_files:\n",
    "    all_documents.extend(load_and_split_tax_law(file))\n",
    "# load - ì„¸ë²•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7863fac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = \"tax_law\"\n",
    "PERSIST_DIRECTORY = \"tax\"\n",
    "\n",
    "def set_vector_store(documents):\n",
    "    embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "    return Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embedding_model,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        persist_directory=PERSIST_DIRECTORY\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d586fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Œ vector store ìƒì„±\n",
    "# vector_store = set_vector_store(all_documents)\n",
    "\n",
    "# retriever = vector_store.as_retriever(\n",
    "#     search_type=\"mmr\",\n",
    "#     search_kwargs={\"k\": 5, \"fetch_k\": 10}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ce2c72fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Template ìƒì„±\n",
    "messages = [\n",
    "        (\"ai\", \"\"\"\n",
    "        ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ì„¸ë²•ì— ëŒ€í•´ ì „ë¬¸ì ìœ¼ë¡œ í•™ìŠµëœ AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì €ì¥ëœ ì„¸ë²• ì¡°í•­ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.\n",
    "\n",
    "        - ëª¨ë“  ë‹µë³€ì€ í•™ìŠµëœ ì„¸ë²• ë°ì´í„° ë‚´ì—ì„œë§Œ ìœ íš¨í•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ë°ì´í„°ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ê±°ë‚˜ ì„ì˜ë¡œ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "        - ì§ˆë¬¸ì— ëª…í™•í•œ ë‹µë³€ì´ ì—†ê±°ë‚˜ ë°ì´í„° ë‚´ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°, ì •ì§í•˜ê²Œ \"ì˜ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤.\"ë¼ê³  ë§í•˜ê³ , ìƒˆë¡œìš´ ì§ˆë¬¸ì„ ìœ ë„í•˜ì„¸ìš”.\n",
    "        - ì§ˆë¬¸ì´ í¬í•¨ëœ ì¡°í•­ë¿ ì•„ë‹ˆë¼, í•„ìš” ì‹œ ì„œë¡œ ì—°ê´€ëœ ë‹¤ë¥¸ ì¡°í•­ë„ ì°¸ê³ í•˜ì—¬ ë‹µë³€ì˜ ì •í™•ì„±ê³¼ ì™„ì„±ë„ë¥¼ ë†’ì´ì„¸ìš”.\n",
    "        - ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ë‹µë³€ì„ êµ¬ì„±í•˜ë©°, ì¤‘ìš”í•œ í‚¤ì›Œë“œë‚˜ ë²• ì¡°í•­ì€ ëª…í™•íˆ í‘œì‹œí•˜ì„¸ìš”.\n",
    "        - ì„¸ë²•ê³¼ ê´€ë ¨ëœ ë³µì¡í•œ ì§ˆë¬¸ì— ëŒ€í•´ì„œëŠ” ê´€ë ¨ ì¡°í•­ ë²ˆí˜¸ì™€ ìš”ì•½ëœ ë‚´ìš©ì„ í¬í•¨í•˜ì—¬ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.\n",
    "        \n",
    "        ì¶”ê°€ ê·œì¹™:\n",
    "        ë‹µë³€ì€ ê°„ê²°í•˜ê³  ëª…ë£Œí•˜ê²Œ ì‘ì„±í•˜ë˜, í•„ìš”í•œ ê²½ìš° ê´€ë ¨ ì¡°í•­ì˜ ì „ë¬¸ì„ ì¶”ê°€ì ìœ¼ë¡œ ì¸ìš©í•˜ì„¸ìš”.\n",
    "        ì„¸ë²• ìš©ì–´ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ ì„¤ëª…í•˜ì—¬ ë¹„ì „ë¬¸ê°€ë„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ í•˜ì„¸ìš”.\n",
    "        ì§ˆë¬¸ì„ ì™„ì „íˆ ì´í•´í•˜ê¸° ì–´ë µê±°ë‚˜ ëª¨í˜¸í•  ê²½ìš°, ì‚¬ìš©ìê°€ êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸ì„ ë‹¤ì‹œ ì‘ì„±í•  ìˆ˜ ìˆë„ë¡ ìœ ë„í•˜ëŠ” í›„ì† ì§ˆë¬¸ì„ í•˜ì„¸ìš”.\n",
    "\n",
    "\të‹µë³€ í›„, ì‚¬ìš©ìì—ê²Œ í•„ìš”í•  ê²ƒ ê°™ì€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‘ ê°€ì§€ í›„ì† ì§ˆë¬¸ì„ ì œì•ˆí•˜ì„¸ìš”. ê° ì§ˆë¬¸ì˜ ì•ë’¤ì— í•œ ì¤„ì”© ë„ì–´ì“°ê¸°ë¥¼ í•˜ì„¸ìš”. ì´ ì§ˆë¬¸ì€ ì›ë˜ ì£¼ì œì™€ ê´€ë ¨ëœ ë‚´ìš©ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\tíŠ¹ì • ë²•ë¥  ì¡°í•­ì´ë‚˜ ì œë„ê°€ ì–¸ê¸‰ë  ê²½ìš°, ê·¼ê±°ê°€ ë˜ëŠ” ì„¸ë²• ì¡°ë¬¸, ì‹œí–‰ë ¹, ë˜ëŠ” ê´€ë ¨ ìë£Œë¥¼ ëª…ì‹œí•©ë‹ˆë‹¤.\n",
    "        ëª¨ë“  ë‹µë³€ì€ ì‚¬ìš©ìì—ê²Œ ë²•ì  ì¡°ì–¸ì´ ì•„ë‹Œ ì •ë³´ ì œê³µ ëª©ì ìœ¼ë¡œ ì‘ì„±ëœ ê²ƒì„ì„ ëª…í™•íˆ í•©ë‹ˆë‹¤. \n",
    "\t{context}\")\"\"\"\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "]\n",
    "prompt_template = ChatPromptTemplate(messages)\n",
    "# ëª¨ë¸\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# output parser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Chain êµ¬ì„± retriever(ê´€ë ¨ë¬¸ì„œ ì¡°íšŒ) -> prompt_template(prompt ìƒì„±) -> model(ì •ë‹µ) -> output parser\n",
    "chain = {\"context\":retriever, \"question\": RunnablePassthrough()} | prompt_template | model | parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2e44d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain.invoke(\"ê°œë³„ì†Œë¹„ì„¸ë²•ì´ ë­ì•¼?\")\n",
    "# chain.invoke(\"ê°œë³„ì†Œë¹„ì„¸ë²•ì´ ì œ1ì¡°ê°€ ë­ì•¼\")\n",
    "# chain.invoke(\"êµí†µ_ì—ë„ˆì§€_í™˜ê²½ì„¸ë²• ë­ì•¼?\")\n",
    "chain.invoke(\"ì¡°ì„¸ë²” ì²˜ë²Œì ˆì°¨ë²•ì˜ ì •ì˜í•´ì¤˜\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8717ab88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e748211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
