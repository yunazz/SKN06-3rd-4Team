{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf717c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache, SQLiteCache\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "COLLECTION_NAME = \"tax_law\"\n",
    "PERSIST_DIRECTORY = \"tax\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a070fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_file_names(folder_path):\n",
    "    \"\"\"\n",
    "    ì£¼ì–´ì§„ í´ë” ë‚´ì— ìˆëŠ” PDF íŒŒì¼ë“¤ì˜ ì´ë¦„ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): PDF íŒŒì¼ì´ ìˆëŠ” í´ë”ì˜ ê²½ë¡œ.\n",
    "\n",
    "    Returns:\n",
    "        list: PDF íŒŒì¼ ì´ë¦„ë“¤ì˜ ë¦¬ìŠ¤íŠ¸.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # í´ë” ë‚´ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°\n",
    "        all_files = os.listdir(folder_path)\n",
    "        \n",
    "        # í™•ì¥ìê°€ '.pdf'ì¸ íŒŒì¼ë§Œ í•„í„°ë§\n",
    "        pdf_files = [file.replace(\".pdf\",\"\") for file in all_files if file.lower().endswith('.pdf')]\n",
    "        \n",
    "        return pdf_files\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: í´ë” '{folder_path}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06504bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split_tax_law(file_path,repeat_pattern):\n",
    "    \"\"\"\n",
    "    PDF íŒŒì¼ì„ ë¡œë“œí•˜ê³ , ë°˜ë³µ í…ìŠ¤íŠ¸ ì œê±°, ì¡°í•­ ê¸°ì¤€ìœ¼ë¡œ ë¶„í•  ë° ì—°ê²° í›„ ì„ë² ë”© ì¤€ë¹„.\n",
    "    Args:\n",
    "        file_path (str): PDF íŒŒì¼ ê²½ë¡œ.\n",
    "    Returns:\n",
    "        list: ì—°ê²°ëœ í…ìŠ¤íŠ¸ ì¡°ê°ë“¤ì˜ ë¦¬ìŠ¤íŠ¸.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    from langchain.document_loaders import PyMuPDFLoader\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "    # PDF ë¡œë“œ\n",
    "    loader = PyMuPDFLoader(file_path)\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # ì „ì²´ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°\n",
    "    full_text = \" \".join([doc.page_content for doc in documents])\n",
    "\n",
    "    # 1. ë°˜ë³µ í…ìŠ¤íŠ¸ ì œê±°\n",
    "    full_text = re.sub(repeat_pattern, \"\", full_text)\n",
    "\n",
    "    # 2. 'ì œnì¡°'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• \n",
    "    split_pattern = r\"\\n(ì œ\\d+ì¡°[^\\s]*)\"\n",
    "    chunks = re.split(split_pattern, full_text)\n",
    "\n",
    "    # 3. 'ì œnì¡°'ì™€ ì—°ê²°í•˜ì—¬ ì™„ì „í•œ ë¬¸ë‹¨ êµ¬ì„± + ë¶€ì¹™ ì²˜ë¦¬\n",
    "    connected_chunks = []\n",
    "    current_chunk = \"\"\n",
    "    is_buchik_section = False  # ë¶€ì¹™ ì—¬ë¶€ í”Œë˜ê·¸\n",
    "\n",
    "    for chunk in chunks:\n",
    "        if re.search(r\"\\n\\s*<ë¶€ì¹™>\", chunk):  # ë¶€ì¹™ ì‹œì‘ ì—¬ë¶€ í™•ì¸\n",
    "            is_buchik_section = True\n",
    "\n",
    "        if chunk.startswith(\"ì œ\") and \"ì¡°\" in chunk:  # ìƒˆë¡œìš´ ì¡°í•­ ì‹œì‘\n",
    "            if is_buchik_section:  # ë¶€ì¹™ ì„¹ì…˜ì´ë¼ë©´ ì ‘ë‘ì‚¬ ì¶”ê°€\n",
    "                chunk = \"ë¶€ì¹™-\" + chunk\n",
    "\n",
    "            if current_chunk:  # ì´ì „ ì¡°í•­ ì €ì¥\n",
    "                connected_chunks.append(current_chunk.strip())\n",
    "            current_chunk = chunk  # ìƒˆ ì¡°í•­ìœ¼ë¡œ ì‹œì‘\n",
    "        else:\n",
    "            current_chunk += f\" {chunk}\"  # ê¸°ì¡´ ì¡°í•­ì— ë‚´ìš© ì¶”ê°€\n",
    "\n",
    "    if current_chunk:\n",
    "        connected_chunks.append(current_chunk.strip())\n",
    "\n",
    "\n",
    "    return connected_chunks, full_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6232293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_store(pdf_files):\n",
    "    \"\"\"\n",
    "    PDF íŒŒì¼ë“¤ì„ ì²˜ë¦¬í•˜ì—¬ ì„ë² ë”©ì„ Chroma Vector Storeì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        pdf_files (list): PDF íŒŒì¼ ì´ë¦„ë“¤ì˜ ë¦¬ìŠ¤íŠ¸.\n",
    "        vector_store_path (str): Chroma Vector Storeë¥¼ ì €ì¥í•  ê²½ë¡œ.\n",
    "    \"\"\"\n",
    "    from langchain_chroma import Chroma\n",
    "    from langchain_core.documents import Document\n",
    "    \n",
    "    # ê° PDF íŒŒì¼ì— ëŒ€í•´ ì„ë² ë”© ì²˜ë¦¬\n",
    "    all_docs = []\n",
    "    \n",
    "    for file in pdf_files:\n",
    "        path = f\"data/tax_law/{file}.pdf\"  # PDF íŒŒì¼ ê²½ë¡œ\n",
    "        repeat_pattern = rf\"ë²•ì œì²˜\\s*\\d+\\s*êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„°\\n{file.replace('_', ' ')}\\n\" \n",
    "        chunks, full_text = load_and_split_tax_law(path, repeat_pattern)\n",
    "        \n",
    "\n",
    "        for idx, chunk in enumerate(chunks):\n",
    "            _doc = Document(metadata={\"title\": file, \"full_text\": full_text[idx], }, page_content=chunk),\n",
    "            all_docs.extend(_doc)\n",
    "\n",
    "    embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "    vector_store = Chroma.from_documents(\n",
    "        documents=all_docs,\n",
    "        embedding=embedding_model,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        persist_directory=PERSIST_DIRECTORY\n",
    "    )\n",
    "        \n",
    "    return vector_store\n",
    "        \n",
    "folder_path = \"data/tax_law\" \n",
    "pdf_files = get_pdf_file_names(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc50b674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Œ ì¤‘ë³µ ì €ì¥ ë  ìˆ˜ ìˆì–´ì„œ ì£¼ì„ ì²˜ë¦¬í•¨!\n",
    "# vector_store = get_vector_store(pdf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6bd5100",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# vector_store =  Chroma(\n",
    "#     collection_name=COLLECTION_NAME,\n",
    "#     persist_directory=PERSIST_DIRECTORY,\n",
    "#     embedding_function=embedding_model,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1462a847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5733"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b8711ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\":5, \"fetch_k\":10}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f365d0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ace68f09-666b-4e17-83e7-d5ecb64ef5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Template ìƒì„±\n",
    "messages = [\n",
    "        (\"ai\", \"\"\"\n",
    "        ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ì„¸ë²•ì— ëŒ€í•´ ì „ë¬¸ì ìœ¼ë¡œ í•™ìŠµëœ AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì €ì¥ëœ ì„¸ë²• ì¡°í•­ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.\n",
    "\n",
    "        - ëª¨ë“  ë‹µë³€ì€ í•™ìŠµëœ ì„¸ë²• ë°ì´í„° ë‚´ì—ì„œë§Œ ìœ íš¨í•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ë°ì´í„°ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ê±°ë‚˜ ì„ì˜ë¡œ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "        - ì§ˆë¬¸ì— ëª…í™•í•œ ë‹µë³€ì´ ì—†ê±°ë‚˜ ë°ì´í„° ë‚´ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°, ì •ì§í•˜ê²Œ \"ì˜ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤.\"ë¼ê³  ë§í•˜ê³ , ìƒˆë¡œìš´ ì§ˆë¬¸ì„ ìœ ë„í•˜ì„¸ìš”.\n",
    "        - ì§ˆë¬¸ì´ í¬í•¨ëœ ì¡°í•­ë¿ ì•„ë‹ˆë¼, í•„ìš” ì‹œ ì„œë¡œ ì—°ê´€ëœ ë‹¤ë¥¸ ì¡°í•­ë„ ì°¸ê³ í•˜ì—¬ ë‹µë³€ì˜ ì •í™•ì„±ê³¼ ì™„ì„±ë„ë¥¼ ë†’ì´ì„¸ìš”.\n",
    "        - ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ë‹µë³€ì„ êµ¬ì„±í•˜ë©°, ì¤‘ìš”í•œ í‚¤ì›Œë“œë‚˜ ë²• ì¡°í•­ì€ ëª…í™•íˆ í‘œì‹œí•˜ì„¸ìš”.\n",
    "        - ì„¸ë²•ê³¼ ê´€ë ¨ëœ ë³µì¡í•œ ì§ˆë¬¸ì— ëŒ€í•´ì„œëŠ” ê´€ë ¨ ì¡°í•­ ë²ˆí˜¸ì™€ ìš”ì•½ëœ ë‚´ìš©ì„ í¬í•¨í•˜ì—¬ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.\n",
    "        \n",
    "        ì¶”ê°€ ê·œì¹™:\n",
    "        ë‹µë³€ì€ ê°„ê²°í•˜ê³  ëª…ë£Œí•˜ê²Œ ì‘ì„±í•˜ë˜, í•„ìš”í•œ ê²½ìš° ê´€ë ¨ ì¡°í•­ì˜ ì „ë¬¸ì„ ì¶”ê°€ì ìœ¼ë¡œ ì¸ìš©í•˜ì„¸ìš”.\n",
    "        ì„¸ë²• ìš©ì–´ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ ì„¤ëª…í•˜ì—¬ ë¹„ì „ë¬¸ê°€ë„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ í•˜ì„¸ìš”.\n",
    "        ì§ˆë¬¸ì„ ì™„ì „íˆ ì´í•´í•˜ê¸° ì–´ë µê±°ë‚˜ ëª¨í˜¸í•  ê²½ìš°, ì‚¬ìš©ìê°€ êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸ì„ ë‹¤ì‹œ ì‘ì„±í•  ìˆ˜ ìˆë„ë¡ ìœ ë„í•˜ëŠ” í›„ì† ì§ˆë¬¸ì„ í•˜ì„¸ìš”.\n",
    "        \n",
    "        {context}\")\"\"\"\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "]\n",
    "prompt_template = ChatPromptTemplate(messages)\n",
    "# ëª¨ë¸\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# output parser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Chain êµ¬ì„± retriever(ê´€ë ¨ë¬¸ì„œ ì¡°íšŒ) -> prompt_template(prompt ìƒì„±) -> model(ì •ë‹µ) -> output parser\n",
    "chain = {\"context\":retriever, \"question\": RunnablePassthrough()} | prompt_template | model | parser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b2e44d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì¡°ì„¸ë²” ì²˜ë²Œì ˆì°¨ë²•ì—ì„œ ì‚¬ìš©í•˜ëŠ” ìš©ì–´ì˜ ì •ì˜ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\\n\\n1. **ì¡°ì„¸ë²”ì¹™í–‰ìœ„**: ì´ëŠ” ã€Œì¡°ì„¸ë²” ì²˜ë²Œë²•ã€ ì œ3ì¡°ë¶€í„° ì œ16ì¡°ê¹Œì§€ì˜ ì£„ì— í•´ë‹¹í•˜ëŠ” ìœ„ë°˜í–‰ìœ„ë¥¼ ë§í•©ë‹ˆë‹¤.\\n   \\n2. **ì¡°ì„¸ë²”ì¹™ì‚¬ê±´**: ì¡°ì„¸ë²”ì¹™í–‰ìœ„ì˜ í˜ì˜ê°€ ìˆëŠ” ì‚¬ê±´ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\\n\\n3. **ì¡°ì„¸ë²”ì¹™ì¡°ì‚¬**: ì„¸ë¬´ê³µë¬´ì›ì´ ì¡°ì„¸ë²”ì¹™í–‰ìœ„ ë“±ì„ í™•ì •í•˜ê¸° ìœ„í•˜ì—¬ ì¡°ì„¸ë²”ì¹™ì‚¬ê±´ì— ëŒ€í•˜ì—¬ í–‰í•˜ëŠ” ì¡°ì‚¬í™œë™ì„ ë§í•©ë‹ˆë‹¤.\\n\\n4. **ì„¸ë¬´ê³µë¬´ì›**: ì„¸ë¬´ì— ì¢…ì‚¬í•˜ëŠ” ê³µë¬´ì›ìœ¼ë¡œì„œ, ì§€ë°©êµ­ì„¸ì²­ ì†Œì† ê³µë¬´ì›ì´ë‚˜ ì„¸ë¬´ì„œ ì†Œì† ê³µë¬´ì›ì˜ ê²½ìš° ê°ê° ì†Œì† ì§€ë°©êµ­ì„¸ì²­ì¥ì˜ ì œì²­ìœ¼ë¡œ í•´ë‹¹ ì§€ë°©êµ­ì„¸ì²­ì´ë‚˜ ì„¸ë¬´ì„œì˜ ì†Œì¬ì§€ë¥¼ ê´€í• í•˜ëŠ” ì§€ë°©ê²€ì°°ì²­ì˜ ê²€ì‚¬ì¥ì´ ì§€ëª…í•˜ëŠ” ê³µë¬´ì›ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\\n\\nì´ ì •ì˜ë“¤ì€ ì¡°ì„¸ë²” ì²˜ë²Œì ˆì°¨ë²• ì œ2ì¡°ì— ëª…ì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¶”ê°€ì ìœ¼ë¡œ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain.invoke(\"ê°œë³„ì†Œë¹„ì„¸ë²•ì´ ë­ì•¼?\")\n",
    "# chain.invoke(\"ê°œë³„ì†Œë¹„ì„¸ë²•ì´ ì œ1ì¡°ê°€ ë­ì•¼\")\n",
    "# chain.invoke(\"êµí†µ_ì—ë„ˆì§€_í™˜ê²½ì„¸ë²• ë­ì•¼?\")\n",
    "chain.invoke(\"ì¡°ì„¸ë²” ì²˜ë²Œì ˆì°¨ë²•ì˜ ì •ì˜í•´ì¤˜\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8177863b-e4d9-44c3-9af2-0acbb4482548",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
