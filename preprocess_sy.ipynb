{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tabula import read_pdf\n",
    "import PyPDF2\n",
    "from langchain_core.documents import Document\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "# ğŸ“Œ ê²½ë¡œ ë° ì„¤ì •\n",
    "pdf_path = \"data/tax_etc/ì—°ë§ì •ì‚°_Q&A.pdf\"\n",
    "COLLECTION_NAME = \"tax1\"\n",
    "PERSIST_DIRECTORY = \"tax1\"\n",
    "\n",
    "\n",
    "# ğŸ“Œ í˜ì´ì§€ ë²ˆí˜¸ ë° ã€ã€‘ í˜•ì‹ ì œê±° í•¨ìˆ˜\n",
    "def clean_page_numbers_and_brackets(text):\n",
    "\n",
    "    #  í˜ì´ì§€ ë²ˆí˜¸ íŒ¨í„´ ì œê±° (- ìˆ«ì - í˜•íƒœ)\n",
    "    text = re.sub(r'^- \\d{1,3} -', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # ã€ã€‘ë¡œ ë‘˜ëŸ¬ì‹¸ì¸ í…ìŠ¤íŠ¸ ì œê±°\n",
    "    text = re.sub(r'ã€.*?ã€‘', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "\n",
    "# ğŸ“Œ ì„ë² ë”© ëª¨ë¸ ì„¤ì •\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# ğŸ“Œ ëª¨ë“  í˜ì´ì§€ ì²˜ë¦¬\n",
    "documents = []\n",
    "\n",
    "# ğŸ“„ **í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° í™•ì¸\n",
    "try:\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        num_pages = len(reader.pages)\n",
    "        \n",
    "        # 23í˜ì´ì§€ë¶€í„° ì‹œì‘\n",
    "        for page_num in range(23, num_pages):\n",
    "            page = reader.pages[page_num]\n",
    "            page_text = page.extract_text() or \"\"\n",
    "            cleaned_text = clean_page_numbers_and_brackets(page_text)\n",
    "            \n",
    "            # if cleaned_text:\n",
    "            #     # í™•ì¸ìš© ì¶œë ¥\n",
    "            #     print(f\"\\nğŸ“„ [Page {page_num + 1}] Extracted Text:\")\n",
    "            #     print(cleaned_text[:300])  # ì²˜ìŒ 300ìë§Œ ì¶œë ¥\n",
    "                \n",
    "            #     documents.append(Document(\n",
    "            #         page_content=cleaned_text,\n",
    "            #         metadata={\n",
    "            #             \"source\": pdf_path,\n",
    "            #             \"type\": \"text\",\n",
    "            #             \"page\": page_num + 1\n",
    "            #         }\n",
    "            #     ))\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Text Extraction Error: {e}\")\n",
    "\n",
    "try:\n",
    "    tables = read_pdf(\n",
    "        pdf_path,\n",
    "        pages=\"23-\",\n",
    "        multiple_tables=True,\n",
    "        lattice=True,  # ê²©ìí˜• í‘œ ì¸ì‹\n",
    "        guess=True     # í‘œ ìë™ ì¸ì‹ ìµœì í™”\n",
    "    )\n",
    "    if tables:\n",
    "        for i, table in enumerate(tables):\n",
    "            table_text = table.to_string(index=False, header=True)\n",
    "            # if table_text.strip():  # ë¹ˆ ë¬¸ìì—´ ë°©ì§€\n",
    "            #     print(f\"\\nğŸ“Š [Table {i + 1}] Extracted Table:\")\n",
    "            #     print(table_text[:300])  # ì²˜ìŒ 300ìë§Œ ì¶œë ¥\n",
    "\n",
    "            #     documents.append(Document(\n",
    "            #         page_content=table_text,\n",
    "            #         metadata={\n",
    "            #             \"source\": pdf_path,\n",
    "            #             \"type\": \"table\",\n",
    "            #             \"page\": 23,\n",
    "            #             \"table_index\": i + 1\n",
    "            #         }\n",
    "            #     ))\n",
    "    else:\n",
    "        print(\"âš ï¸ No tables were detected on the specified pages.\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Table Extraction Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Œ **í…ìŠ¤íŠ¸ ë¶„í•  (Splitting)** ğŸ”¥\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # í•˜ë‚˜ì˜ ì²­í¬ì— ë“¤ì–´ê°ˆ ìµœëŒ€ ë¬¸ì ìˆ˜\n",
    "    chunk_overlap=150  # ì²­í¬ ê°„ ê²¹ì¹˜ëŠ” ë¬¸ì ìˆ˜\n",
    ")\n",
    "\n",
    "# ğŸ”„ ë¬¸ì„œ ë¶„í• \n",
    "split_documents = text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ğŸ“Œ Chroma ë²¡í„° ìŠ¤í† ì–´ì— ì €ì¥\n",
    "# if documents:\n",
    "#     vector_store = Chroma.from_documents(\n",
    "#         documents=documents,\n",
    "#         embedding=embedding_model,\n",
    "#         collection_name=COLLECTION_NAME,\n",
    "#         persist_directory=PERSIST_DIRECTORY\n",
    "#     )\n",
    "#     print(f\"âœ… Successfully stored {len(documents)} documents in the vector store.\")\n",
    "# else:\n",
    "#     print(\"âš ï¸ No documents to store in the vector database.\")\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "        documents=split_documents,\n",
    "        embedding=embedding_model,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        persist_directory=PERSIST_DIRECTORY\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\":5, \"fetch_k\":10}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt Template ìƒì„±\n",
    "messages = [\n",
    "        (\"ai\", \"\"\"\n",
    "        ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ì„¸ë²•ì— ëŒ€í•´ ì „ë¬¸ì ìœ¼ë¡œ í•™ìŠµëœ AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì €ì¥ëœ ì„¸ë²• ì¡°í•­ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.\n",
    "\n",
    "        - ëª¨ë“  ë‹µë³€ì€ í•™ìŠµëœ ì„¸ë²• ë°ì´í„° ë‚´ì—ì„œë§Œ ìœ íš¨í•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ë°ì´í„°ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ê±°ë‚˜ ì„ì˜ë¡œ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "        - ì§ˆë¬¸ì— ëª…í™•í•œ ë‹µë³€ì´ ì—†ê±°ë‚˜ ë°ì´í„° ë‚´ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°, ì •ì§í•˜ê²Œ \"ì˜ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤.\"ë¼ê³  ë§í•˜ê³ , ìƒˆë¡œìš´ ì§ˆë¬¸ì„ ìœ ë„í•˜ì„¸ìš”.\n",
    "        - ì§ˆë¬¸ì´ í¬í•¨ëœ ì¡°í•­ë¿ ì•„ë‹ˆë¼, í•„ìš” ì‹œ ì„œë¡œ ì—°ê´€ëœ ë‹¤ë¥¸ ì¡°í•­ë„ ì°¸ê³ í•˜ì—¬ ë‹µë³€ì˜ ì •í™•ì„±ê³¼ ì™„ì„±ë„ë¥¼ ë†’ì´ì„¸ìš”.\n",
    "        - ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ë‹µë³€ì„ êµ¬ì„±í•˜ë©°, ì¤‘ìš”í•œ í‚¤ì›Œë“œë‚˜ ë²• ì¡°í•­ì€ ëª…í™•íˆ í‘œì‹œí•˜ì„¸ìš”.\n",
    "        - ì„¸ë²•ê³¼ ê´€ë ¨ëœ ë³µì¡í•œ ì§ˆë¬¸ì— ëŒ€í•´ì„œëŠ” ê´€ë ¨ ì¡°í•­ ë²ˆí˜¸ì™€ ìš”ì•½ëœ ë‚´ìš©ì„ í¬í•¨í•˜ì—¬ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.\n",
    "        \n",
    "        ì¶”ê°€ ê·œì¹™:\n",
    "        ë‹µë³€ì€ ê°„ê²°í•˜ê³  ëª…ë£Œí•˜ê²Œ ì‘ì„±í•˜ë˜, í•„ìš”í•œ ê²½ìš° ê´€ë ¨ ì¡°í•­ì˜ ì „ë¬¸ì„ ì¶”ê°€ì ìœ¼ë¡œ ì¸ìš©í•˜ì„¸ìš”.\n",
    "        ì„¸ë²• ìš©ì–´ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ ì„¤ëª…í•˜ì—¬ ë¹„ì „ë¬¸ê°€ë„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ í•˜ì„¸ìš”.\n",
    "        ì§ˆë¬¸ì„ ì™„ì „íˆ ì´í•´í•˜ê¸° ì–´ë µê±°ë‚˜ ëª¨í˜¸í•  ê²½ìš°, ì‚¬ìš©ìê°€ êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸ì„ ë‹¤ì‹œ ì‘ì„±í•  ìˆ˜ ìˆë„ë¡ ìœ ë„í•˜ëŠ” í›„ì† ì§ˆë¬¸ì„ í•˜ì„¸ìš”.\n",
    "        #ì¶”ê°€í•œ ë¶€ë¶„#\n",
    "        ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ì •í™•í•œ ë²•ë ¹ëª…ì´ë‚˜ ì¡°í•­ì„ ë‹¤ë£¨ê³  ìˆì§€ ì•Šë”ë¼ë„, ì§ˆë¬¸ì˜ ë§¥ë½ê³¼ í‚¤ì›Œë“œë¥¼ ë¶„ì„í•˜ì—¬ ê°€ì¥ ê°€ê¹Œìš´ ê´€ë ¨ ë²•ë ¹ ë° ì¡°í•­ì„ ì°¾ì•„ ë‹µë³€í•˜ì„¸ìš”.\n",
    "        ë²•ë ¹ëª…ì—ì„œ ë²•ê³¼ ê°™ì€ ì ‘ë¯¸ì–´ê°€ ìƒëµëœ ê²½ìš°ì—ë„ ë™ì¼í•œ ì˜ë¯¸ë¡œ ê°„ì£¼í•˜ì„¸ìš”.\n",
    "        ë²•ë ¹ëª…ê³¼ ì¡°í•­ ë²ˆí˜¸ê°€ ë‹¤ì†Œ ë¶€ì •í™•í•˜ê²Œ ì…ë ¥ë˜ì—ˆë”ë¼ë„, AIê°€ ê°€ëŠ¥í•œ í•œ ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ íŒŒì•…í•˜ì—¬ ì˜¬ë°”ë¥¸ ë²•ë ¹ê³¼ ì¡°í•­ìœ¼ë¡œ ì—°ê²°í•˜ì„¸ìš”.\n",
    "        ì§ˆë¬¸ì— íŠ¹ì • ì¡°í•­(ì˜ˆ: ì œ1ì¡°)ì´ í¬í•¨ëœ ê²½ìš°, í•´ë‹¹ ì¡°í•­ì˜ ì œëª©, ë³¸ë¬¸, ì—°í˜, ì£¼ì„ì„ ì¢…í•©ì ìœ¼ë¡œ í™•ì¸í•´ ë‹µë³€í•˜ì„¸ìš”.\n",
    "        \n",
    "        \n",
    "        {context}\")\"\"\"\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "]\n",
    "prompt_template = ChatPromptTemplate(messages)\n",
    "# ëª¨ë¸\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# output parser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Chain êµ¬ì„± retriever(ê´€ë ¨ë¬¸ì„œ ì¡°íšŒ) -> prompt_template(prompt ìƒì„±) -> model(ì •ë‹µ) -> output parser\n",
    "chain = {\"context\":retriever, \"question\": RunnablePassthrough()} | prompt_template | model | parser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì•„ë‹ˆìš”, ì–´ë¦°ì´ì§‘ ì…ì†Œë£ŒëŠ” êµìœ¡ë¹„ ì„¸ì•¡ê³µì œ ëŒ€ìƒì— í¬í•¨ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì–´ë¦°ì´ì§‘ì— ì§€ì¶œí•œ êµìœ¡ë¹„ ì¤‘ì—ì„œ êµìœ¡ë¹„ ì„¸ì•¡ê³µì œ ëŒ€ìƒì— í¬í•¨ë˜ëŠ” í•­ëª©ì€ ã€Œì˜ìœ ì•„ë³´ìœ¡ë²•ã€ ì œ38ì¡°ì— ë”°ë¼ ì •í•´ì§„ ë³´ìœ¡ë£Œì™€ íŠ¹ë³„í™œë™ë¹„(ë„ì„œ êµ¬ì…ë¹„ í¬í•¨, ì¬ë£Œë¹„ ì œì™¸)ì…ë‹ˆë‹¤. ë”°ë¼ì„œ ì…ì†Œë£Œ, í˜„ì¥í•™ìŠµë¹„, ì°¨ëŸ‰ ìš´í–‰ë¹„ ë“±ì€ ì‹¤ë¹„ ì„±ê²©ì˜ ê¸°íƒ€ í•„ìš” ê²½ë¹„ë¡œ ê°„ì£¼ë˜ì–´ êµìœ¡ë¹„ ê³µì œ ëŒ€ìƒì— í•´ë‹¹í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain.invoke(\"ì‚¬ì—…ì†Œë“ì´ 4ì²œë§Œì› ì´í•˜ì¼ë•Œ ì†Œìƒê³µì¸ ê³µì œë¶€ê¸ˆ ì†Œë“ê³µì œì˜ í•œë„ë¥¼ ì•Œë ¤ì¤˜\")\n",
    "# chain.invoke(\"ì†Œìƒê³µì¸ ê³µì œë¶€ê¸ˆ ì†Œë“ê³µì œì˜ í•œë„ëŠ” ì–¼ë§ˆì•¼? ì‚¬ì—…ì†Œë“ì´ 1ì–µì„ ë„˜ì–´ê°”ì„ ë•Œ\")\n",
    "# chain.invoke(\"ê·¼ë¡œì†Œë“ ì‚°ì¶œì„¸ì•¡ì´ 130ë§Œì› ì´í•˜ì¼ ë•Œ ì„¸ì•¡ê³µì œê¸ˆì•¡ì„ ì•Œë ¤ì¤˜\")\n",
    "chain.invoke(\"ì–´ë¦°ì´ì§‘ ì…ì†Œë£ŒëŠ” êµìœ¡ë¹„ ì„¸ì•¡ê³µì œ ëŒ€ìƒì— í¬í•¨ë˜ì–´ìˆì–´?\")\n",
    "# chain.invoke(\"ê·¼ë¡œì œê³µ ê¸°ê°„ë™ì•ˆ ì§€ì¶œí•œ ë¹„ìš©ì— ëŒ€í•´ì„œë§Œ ê³µì œê°€ëŠ¥í•œ í•­ëª©ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
