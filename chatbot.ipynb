{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# def load_file_law(filename):\n",
    "#     doc_file = f\"data/tax_law/{filename}.doc\"\n",
    "# load_file_law('ê°œë³„ì†Œë¹„ì„¸ë²•')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¸ë²• ì±—ë´‡\n",
    "#### ë°ì´í„° ìˆ˜ì§‘: ê°œë³„ì†Œë¹„ì„¸ë²•\n",
    "- ê°œë³„ì†Œë¹„ì„¸ë²•.pdf\n",
    "- ê°œë³„ì†Œë¹„ì„¸ë²•_ì‹œí–‰ê·œì¹™.pdf\n",
    "- ê°œë³„ì†Œë¹„ì„¸ë²•_ì‹œí–‰ë ¹.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### íŒ¨í‚¤ì§€ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain langchain-huggingface langchain-community langchain-core langchain-text-splitters bitsandbytes docx2txt langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langchain-community pymupdf langchain_chroma langchain_huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì„œ ì „ì²˜ë¦¬ ë° split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_names(folder_path, format=\".pdf\"):\n",
    "    \"\"\"\n",
    "    ì£¼ì–´ì§„ í´ë” ë‚´ì— ìˆëŠ” PDF íŒŒì¼ë“¤ì˜ ì´ë¦„ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    try:\n",
    "        all_files = os.listdir(folder_path)\n",
    "        pdf_files = [file.replace(format,\"\") for file in all_files if file.lower().endswith(format)]\n",
    "        \n",
    "        return pdf_files\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: í´ë” '{folder_path}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.schema import Document\n",
    "import re\n",
    "def load_law(filename):\n",
    "    \n",
    "    \"\"\"\n",
    "    PDF íŒŒì¼ë“¤ì„ ì²˜ë¦¬í•˜ì—¬ ì„ë² ë”©ì„ Chroma Vector Storeì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "\n",
    "    file_path = f\"data/tax_law/{filename}.pdf\"\n",
    "\n",
    "    loader = PyMuPDFLoader(file_path)\n",
    "    load_document = loader.load()\n",
    "\n",
    "    # ì „ì²˜ë¦¬ - ë°˜ë³µ í…ìŠ¤íŠ¸ ì‚­ì œ\n",
    "    delete_patterns = [\n",
    "        rf\"ë²•ì œì²˜\\s*\\d+\\s*êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„°\\n{filename.replace('_', ' ')}\\n\",\n",
    "        r'\\[[\\s\\S]*?\\]', \n",
    "        r'<[\\s\\S]*?>',\n",
    "    ]\n",
    "    \n",
    "    full_text = \" \".join([document.page_content for document in load_document])\n",
    "    \n",
    "    for pattern in delete_patterns:\n",
    "        full_text = re.sub(pattern, \"\", full_text)\n",
    "        full_text = full_text.replace(\"(\", \" (\")\n",
    "    \n",
    "    # ì „ì²˜ë¦¬ - split\n",
    "    split_pattern = r\"\\s*\\n(ì œ\\d+ì¡°(?:ì˜\\d+)?(?:\\([^)]*\\))?)(?=\\s|$)\"\n",
    "    chunks = re.split(split_pattern, full_text)\n",
    "\n",
    "    chunk_docs = []\n",
    "    connected_chunks = [] \n",
    "    current_chunk = \"\"\n",
    "    is_buchik_section = False \n",
    "    \n",
    "    # ì „ì²˜ë¦¬ - ì¼ë°˜ ì¡°í•­ê³¼ ë¶€ì¹™ì˜ ì¡°í•­ê³¼ êµ¬ë³„í•˜ê¸° ìœ„í•´ ì ‘ë‘ì–´ 'ë¶€ì¹™-'ì„ ë„£ìŒ.\n",
    "    for chunk in chunks:\n",
    "        if re.search(r\"\\n\\s*ë¶€ì¹™\", chunk): \n",
    "            is_buchik_section = True\n",
    "\n",
    "        if chunk.startswith(\"ì œ\") and \"ì¡°\" in chunk: \n",
    "            if is_buchik_section:\n",
    "                chunk = \"ë¶€ì¹™-\" + chunk\n",
    "\n",
    "            if current_chunk:\n",
    "                connected_chunks.append(current_chunk.strip())\n",
    "            current_chunk = chunk \n",
    "        else:\n",
    "            current_chunk += f\" {chunk}\" \n",
    "\n",
    "    if current_chunk:\n",
    "        connected_chunks.append(current_chunk.strip())\n",
    "\n",
    "    for chunk in connected_chunks:\n",
    "        pattern =  r\"^(?:ë¶€ì¹™-)?ì œ\\d+ì¡°(?:ì˜\\d*)?(?:\\([^)]*\\))?\"\n",
    "\n",
    "        keyword = ''\n",
    "        keyword += f\"{filename.replace(\"_\", \" \")} \"\n",
    "        \n",
    "        match = re.search(pattern, chunk)\n",
    "        word=''\n",
    "        if match:\n",
    "            word = match.group()\n",
    "            word = re.sub(r'\\s+', ' ', word)\n",
    "            word = re.sub(r'\\(+', ' (', word)\n",
    "        else:\n",
    "            word = \"ê´€ë ¨ ë¶€ì„œ ì—°ë½ì²˜\"\n",
    "        \n",
    "        keyword += word \n",
    "\n",
    "        parts = filename.split(\"_\")\n",
    "\n",
    "        # ê¸°ë³¸ì ìœ¼ë¡œ ë‘ ë¶€ë¶„ì´ ìˆì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒ, ì—†ì„ ê²½ìš° 'ë²•'ë¡œ ê¸°ë³¸ê°’ ì„¤ì •\n",
    "        if len(parts) == 2:\n",
    "            law_name, doc_type = parts\n",
    "        else:\n",
    "            law_name = parts[0]\n",
    "            doc_type = \"ë²•ë¥ \"  # ê¸°ë³¸ê°’ ì„¤ì •\n",
    "\n",
    "        \n",
    "        doc = Document(\n",
    "            metadata={\n",
    "                \"document_type\": doc_type,\n",
    "                \"law_name\": law_name,\n",
    "                \"article_number\": f'{doc_type} {word}',\n",
    "                \"description\": f\"{keyword}ì— ê´€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.\",\n",
    "                \"source\": f'{filename}.pdf', \n",
    "            }, \n",
    "            page_content=chunk\n",
    "        ),\n",
    "        \n",
    "        chunk_docs.extend(doc)\n",
    "        \n",
    "    return chunk_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document_list = []\n",
    "\n",
    "# law_files = get_file_names(\"data/tax_law\")\n",
    "# for file in law_files:\n",
    "#     document_list.extend(load_law(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_list = []\n",
    "document_list.extend(load_law('ê°œë³„ì†Œë¹„ì„¸ë²•'))\n",
    "document_list.extend(load_law('ê°œë³„ì†Œë¹„ì„¸ë²•_ì‹œí–‰ë ¹'))\n",
    "document_list.extend(load_law('ê°œë³„ì†Œë¹„ì„¸ë²•_ì‹œí–‰ê·œì¹™'))\n",
    "len(document_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chromaë¥¼ í™œìš©í•œ vector store êµ¬ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_chroma import Chroma\n",
    "# from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# embeddings = HuggingFaceEmbeddings(model_name='intfloat/multilingual-e5-large-instruct')\n",
    "\n",
    "# COLLECTION_NAME = \"law\"\n",
    "# PERSIST_DIRECTORY = \"vector_store_hf\"\n",
    "\n",
    "# vector_store_hf = Chroma.from_documents(\n",
    "#     documents=document_list,\n",
    "#     embedding=embeddings,\n",
    "#     collection_name=COLLECTION_NAME,\n",
    "#     persist_directory=PERSIST_DIRECTORY\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Œ vector store ìƒì„±\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "COLLECTION_NAME = \"law_5\"\n",
    "PERSIST_DIRECTORY = \"vector_store9\"\n",
    "\n",
    "def set_vector_store(documents):\n",
    "    embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "    return Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embedding_model,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        persist_directory=PERSIST_DIRECTORY\n",
    "    )\n",
    "    \n",
    "vector_store = set_vector_store(document_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain ë§Œë“¤ê¸° \n",
    "- LLM\n",
    "- Prompt Template\n",
    "- Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import  ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "# Prompt Template ìƒì„±\n",
    "messages = [\n",
    "    (\"ai\", \"\"\"\n",
    "    ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ì„¸ë²•ì— ëŒ€í•´ ì „ë¬¸ì ìœ¼ë¡œ í•™ìŠµëœ AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì €ì¥ëœ ì„¸ë²• ì¡°í•­ ë°ì´í„°ì™€ ê´€ë ¨ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  ì‹ ë¢°ì„± ìˆëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”. \n",
    "\n",
    "    **ì—­í•  ë° ê¸°ë³¸ ê·œì¹™**:\n",
    "    - ë‹¹ì‹ ì˜ ì£¼ìš” ì—­í• ì€ ì„¸ë²• ì •ë³´ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ ì „ë‹¬í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "    - ë°ì´í„°ì— ê¸°ë°˜í•œ ì •ë³´ë¥¼ ì œê³µí•˜ë©°, ë°ì´í„°ì— ì—†ëŠ” ë‚´ìš©ì€ ì„ì˜ë¡œ ì¶”ì¸¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "    - ë¶ˆí™•ì‹¤í•œ ê²½ìš°, \"ì˜ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤.\"ë¼ê³  ëª…í™•íˆ ë‹µë³€í•˜ê³ , ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ë” êµ¬ì²´í™”í•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.\n",
    "\n",
    "    **ì§ˆë¬¸ ì²˜ë¦¬ ì ˆì°¨**:\n",
    "    1. **ì§ˆë¬¸ì˜ í•µì‹¬ ë‚´ìš© ì¶”ì¶œ**:\n",
    "        - ì§ˆë¬¸ì„ í˜•íƒœì†Œ ë‹¨ìœ„ë¡œ ë¶„ì„í•˜ì—¬ ì¡°ì‚¬ë¥¼ ë¬´ì‹œí•˜ê³  í•µì‹¬ í‚¤ì›Œë“œë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤. \n",
    "        - ì§ˆë¬¸ì˜ í˜•íƒœê°€ ë‹¤ë¥´ë”ë¼ë„ ë¬¸ë§¥ì˜ ì˜ë„ê°€ ê°™ìœ¼ë©´ ë™ì¼í•œ ì§ˆë¬¸ìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.\n",
    "        - ì˜ˆë¥¼ ë“¤ì–´, \"ê°œë³„ì†Œë¹„ì„¸ë²• 1ì¡° ì•Œë ¤ì¤˜\" ì™€ \"ê°œë³„ì†Œë¹„ì„¸ë²• 1ì¡°ëŠ” ë­ì•¼\" ì™€ \"ê°œë³„ì†Œë¹„ì„¸ë²• 1ì¡°ì˜ ë‚´ìš©ì€?\"ëŠ” ë™ì¼í•œ ì§ˆë¬¸ìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.\n",
    "        - ì˜ˆë¥¼ ë“¤ì–´, \"ì†Œë“ì„¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"ì™€ \"ì†Œë“ì„¸ê°€ ë¬´ì—‡ì¸ê°€ìš”?\"ëŠ” ë™ì¼í•œ ì§ˆë¬¸ìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.\n",
    "   \n",
    "\n",
    "    {context}\n",
    "    \"\"\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "]\n",
    "prompt_template = ChatPromptTemplate(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_kwargs={\"k\":3}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'article_number': 'ì‹œí–‰ê·œì¹™ ê´€ë ¨ ë¶€ì„œ ì—°ë½ì²˜', 'description': 'ê°œë³„ì†Œë¹„ì„¸ë²• ì‹œí–‰ê·œì¹™ ê´€ë ¨ ë¶€ì„œ ì—°ë½ì²˜ì— ê´€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.', 'document_type': 'ì‹œí–‰ê·œì¹™', 'law_name': 'ê°œë³„ì†Œë¹„ì„¸ë²•', 'source': 'ê°œë³„ì†Œë¹„ì„¸ë²•_ì‹œí–‰ê·œì¹™.pdf'}, page_content='ê°œë³„ì†Œë¹„ì„¸ë²• ì‹œí–‰ê·œì¹™\\n \\nê¸°íšì¬ì •ë¶€    (í™˜ê²½ì—ë„ˆì§€ì„¸ì œê³¼) 044-215-4331, 4336\\nê¸°íšì¬ì •ë¶€    (í™˜ê²½ì—ë„ˆì§€ì„¸ì œê³¼ - ìë™ì°¨ ë¶€ë¶„) 044-215-4333, 4336'),\n",
       " Document(metadata={'article_number': 'ì‹œí–‰ë ¹ ì œ1ì¡°', 'description': 'ê°œë³„ì†Œë¹„ì„¸ë²• ì‹œí–‰ë ¹ ì œ1ì¡°ì— ê´€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.', 'document_type': 'ì‹œí–‰ë ¹', 'law_name': 'ê°œë³„ì†Œë¹„ì„¸ë²•', 'source': 'ê°œë³„ì†Œë¹„ì„¸ë²•_ì‹œí–‰ë ¹.pdf'}, page_content='ì œ1ì¡°    (ê³¼ì„¸ë¬¼í’ˆã†ê³¼ì„¸ì¥ì†Œ ë° ê³¼ì„¸ìœ í¥ì¥ì†Œì˜ ì„¸ëª©ë“±) ã€Œê°œë³„ì†Œë¹„ì„¸ë²•ã€ ì œ1ì¡°ì œ6í•­ì— ë”°ë¥¸ ê³¼ì„¸ë¬¼í’ˆì˜ ì„¸ëª©ì€ ë³„í‘œ\\n1ê³¼ ê°™ì´ í•˜ê³ , ê³¼ì„¸ì¥ì†Œì˜ ì¢…ë¥˜ëŠ” ë³„í‘œ 2ì™€ ê°™ì´ í•˜ë©°, ê³¼ì„¸ìœ í¥ì¥ì†Œì˜ ì¢…ë¥˜ëŠ” ìœ í¥ì£¼ì ã†ì™¸êµ­ì¸ì „ìš© ìœ í¥ìŒì‹ì \\në° ê·¸ ë°–ì— ì´ì™€ ìœ ì‚¬í•œ ì¥ì†Œë¡œ í•˜ê³ , ê³¼ì„¸ì˜ì—…ì¥ì†Œì˜ ì¢…ë¥˜ëŠ” ã€Œê´€ê´‘ì§„í¥ë²•ã€ ì œ5ì¡°ì œ1í•­ì— ë”°ë¼ í—ˆê°€ë¥¼ ë°›ì€ ì¹´ì§€ë…¸\\n   (ã€Œíê´‘ì§€ì—­ê°œë°œ ì§€ì›ì— ê´€í•œ íŠ¹ë³„ë²•ã€ ì œ11ì¡°ì— ë”°ë¼ í—ˆê°€ë¥¼ ë°›ì€ ì¹´ì§€ë…¸ë¥¼ í¬í•¨í•œë‹¤)ë¡œ í•œë‹¤.'),\n",
       " Document(metadata={'article_number': 'ë²•ë¥  ì œ4ì¡°', 'description': 'ê°œë³„ì†Œë¹„ì„¸ë²• ì œ4ì¡°ì— ê´€í•œ ë¬¸ì„œì…ë‹ˆë‹¤.', 'document_type': 'ë²•ë¥ ', 'law_name': 'ê°œë³„ì†Œë¹„ì„¸ë²•', 'source': 'ê°œë³„ì†Œë¹„ì„¸ë²•.pdf'}, page_content='ì œ4ì¡°    (ê³¼ì„¸ì‹œê¸°) ê°œë³„ì†Œë¹„ì„¸ëŠ” ë‹¤ìŒ ê° í˜¸ì— ë”°ë¥¸ ë°˜ì¶œ, ìˆ˜ì…ì‹ ê³ , ì…ì¥, ìœ í¥ìŒì‹í–‰ìœ„ ë˜ëŠ” ì˜ì—…í–‰ìœ„ë¥¼ í•  ë•Œì— ê·¸ í–‰ìœ„\\në‹¹ì‹œì˜ ë²•ë ¹ì— ë”°ë¼ ë¶€ê³¼í•œë‹¤. ë‹¤ë§Œ, ì œ3ì¡°ì œ4í˜¸ì˜ ê²½ìš°ì—ëŠ” ã€Œê´€ì„¸ë²•ã€ì— ë”°ë¥¸ë‹¤. \\n1. ë¬¼í’ˆì— ëŒ€í•œ ê°œë³„ì†Œë¹„ì„¸: ê³¼ì„¸ë¬¼í’ˆì„ ì œì¡°ì¥ì—ì„œ ë°˜ì¶œí•  ë•Œ ë˜ëŠ” ìˆ˜ì…ì‹ ê³ ë¥¼ í•  ë•Œ\\n2. ì…ì¥í–‰ìœ„ì— ëŒ€í•œ ê°œë³„ì†Œë¹„ì„¸: ê³¼ì„¸ì¥ì†Œì— ì…ì¥í•  ë•Œ\\n3. ìœ í¥ìŒì‹í–‰ìœ„ì— ëŒ€í•œ ê°œë³„ì†Œë¹„ì„¸: ìœ í¥ìŒì‹í–‰ìœ„ë¥¼ í•  ë•Œ\\n 4. ì˜ì—…í–‰ìœ„ì— ëŒ€í•œ ê°œë³„ì†Œë¹„ì„¸: ê³¼ì„¸ì˜ì—…ì¥ì†Œì˜ ì˜ì—…í–‰ìœ„ë¥¼ í•  ë•Œ')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"ê°œë³„ì†Œë¹„ì„¸ë²• ì œ1ì¡°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = {\"context\": retriever, \"question\": RunnablePassthrough() } | prompt_template | model | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke(\"ê°œë³„ì†Œë¹„ì„¸ë²• ì œ1ì¡°ì— ëŒ€í•´ ì•Œë ¤ì¤˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê°œë³„ì†Œë¹„ì„¸ë²• ì œ1ì¡°ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë‚´ìš©ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤:\n",
      "\n",
      "### ê°œë³„ì†Œë¹„ì„¸ë²• ì œ1ì¡° (ëª©ì )\n",
      "ì´ ë²•ì€ ê°œë³„ì†Œë¹„ì„¸ì˜ ë¶€ê³¼ ë° ì§•ìˆ˜ì— ê´€í•œ ì‚¬í•­ì„ ê·œì •í•¨ìœ¼ë¡œì¨, ì†Œë¹„ì— ëŒ€í•œ ê³µí‰í•œ ì„¸ ë¶€ë‹´ì„ ë„ëª¨í•˜ê³ , êµ­ê°€ ì¬ì •ì˜ ì•ˆì •ì  ìš´ì˜ì— ê¸°ì—¬í•˜ëŠ” ê²ƒì„ ëª©ì ìœ¼ë¡œ í•©ë‹ˆë‹¤.\n",
      "\n",
      "#### ê´€ë ¨ ë‚´ìš© ìš”ì•½:\n",
      "- ê°œë³„ì†Œë¹„ì„¸ëŠ” íŠ¹ì • ì†Œë¹„ì¬ì— ëŒ€í•´ ë¶€ê³¼ë˜ëŠ” ì„¸ê¸ˆì…ë‹ˆë‹¤.\n",
      "- ì´ ë²•ì€ ì†Œë¹„ì— ë”°ë¥¸ ì„¸ ë¶€ë‹´ì˜ í˜•í‰ì„±ì„ ìœ ì§€í•˜ê³ , êµ­ê°€ ì¬ì •ì— ê¸°ì—¬í•˜ê¸° ìœ„í•´ ì œì •ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ ì¡°í•­ì€ ê°œë³„ì†Œë¹„ì„¸ë²•ì˜ ì „ë°˜ì ì¸ ëª©ì ê³¼ ë°©í–¥ì„±ì„ ì œì‹œí•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì¶”ê°€ë¡œ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´, ì–´ë–¤ ë¶€ë¶„ì— ëŒ€í•´ ë” ì•Œê³  ì‹¶ìœ¼ì‹ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
